from torch.utils.data import Dataset
import numpy as np
import random
import cv2
import h5py
import os
import scipy
import torch
class TrainDataset(Dataset):
    def __init__(self, data_root, crop_size, arg=True, bgr2rgb=True, stride=8):
        # Use the absolute path directly
        data_root = '/media/ntu/volume1/home/s124md303_06/MST-plus-plus/dataset/'
        self.crop_size = crop_size
        self.hypers = []
        self.bgrs = []
        self.arg = arg
        h,w = 482,512  # img shape
        self.stride = stride
        self.patch_per_line = (w-crop_size)//stride+1
        self.patch_per_colum = (h-crop_size)//stride+1
        self.patch_per_img = self.patch_per_line*self.patch_per_colum

        hyper_data_path = f'{data_root}/Train_Spec/'
        bgr_data_path = f'{data_root}/Train_RGB/'

        with open(f'{data_root}/split_txt/train_list.txt', 'r') as fin:
            hyper_list = [line.replace('\n','.mat') for line in fin]
            bgr_list = [line.replace('mat','jpg') for line in hyper_list]
        hyper_list.sort()
        bgr_list.sort()
        print(f'len(hyper) of ntire2022 dataset:{len(hyper_list)}')
        print(f'len(bgr) of ntire2022 dataset:{len(bgr_list)}')
        for i in range(len(hyper_list)):
            hyper_path = hyper_data_path + hyper_list[i]
            if 'mat' not in hyper_path:
                continue
            with h5py.File(hyper_path, 'r') as mat:
                hyper =np.float32(np.array(mat['cube']))
            hyper = np.transpose(hyper, [0, 2, 1])
            bgr_path = bgr_data_path + bgr_list[i]
            assert hyper_list[i].split('.')[0] ==bgr_list[i].split('.')[0], 'Hyper and RGB come from different scenes.'
            bgr = cv2.imread(bgr_path)
            if bgr2rgb:
                bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
            bgr = np.float32(bgr)
            bgr = (bgr-bgr.min())/(bgr.max()-bgr.min())
            bgr = np.transpose(bgr, [2, 0, 1])  # [3,482,512]
            self.hypers.append(hyper)
            self.bgrs.append(bgr)
            mat.close()
            print(f'Ntire2022 scene {i} is loaded.')
        self.img_num = len(self.hypers)
        self.length = self.patch_per_img * self.img_num

    def arguement(self, img, rotTimes, vFlip, hFlip):
        # Random rotation
        for j in range(rotTimes):
            img = np.rot90(img.copy(), axes=(1, 2))
        # Random vertical Flip
        for j in range(vFlip):
            img = img[:, :, ::-1].copy()
        # Random horizontal Flip
        for j in range(hFlip):
            img = img[:, ::-1, :].copy()
        return img

    def __getitem__(self, idx):
        stride = self.stride
        crop_size = self.crop_size
        img_idx, patch_idx = idx//self.patch_per_img, idx%self.patch_per_img
        h_idx, w_idx = patch_idx//self.patch_per_line, patch_idx%self.patch_per_line
        bgr = self.bgrs[img_idx]
        hyper = self.hypers[img_idx]
        bgr = bgr[:,h_idx*stride:h_idx*stride+crop_size, w_idx*stride:w_idx*stride+crop_size]
        hyper = hyper[:, h_idx * stride:h_idx * stride + crop_size,w_idx * stride:w_idx * stride + crop_size]
        rotTimes = random.randint(0, 3)
        vFlip = random.randint(0, 1)
        hFlip = random.randint(0, 1)
        if self.arg:
            bgr = self.arguement(bgr, rotTimes, vFlip, hFlip)
            hyper = self.arguement(hyper, rotTimes, vFlip, hFlip)
        return np.ascontiguousarray(bgr), np.ascontiguousarray(hyper)

    def __len__(self):
        return self.patch_per_img*self.img_num
class ValidDataset(Dataset):
    def __init__(self, data_root, bgr2rgb=True):
        data_root = '/media/ntu/volume1/home/s124md303_06/MST-plus-plus/dataset/'
        self.hypers = []
        self.bgrs = []
        hyper_data_path = f'{data_root}Train_Spec/'
        bgr_data_path = f'{data_root}Train_RGB/'
         # Debug statements to check paths
        print(f"Hyper data path: {hyper_data_path}")
        print(f"BGR data path: {bgr_data_path}")
        with open(f'{data_root}/split_txt/valid_list.txt', 'r') as fin:
            hyper_list = [line.replace('\n', '.mat') for line in fin]
            bgr_list = [line.replace('mat','jpg') for line in hyper_list]
        hyper_list.sort()
        bgr_list.sort()
        print(f'len(hyper_valid) of ntire2022 dataset:{len(hyper_list)}')
        print(f'len(bgr_valid) of ntire2022 dataset:{len(bgr_list)}')
         # Load hyper images
        for file_name in os.listdir(hyper_data_path):
            file_path = os.path.join(hyper_data_path, file_name)
            print(f"Checking hyper file: {file_path}")  # Debug print
            if os.path.isfile(file_path):
                self.hypers.append(file_path)
                print(f"Loaded hyper file: {file_path}")  # Confirming file load
            else:
                print(f"File does not exist or is not a file: {file_path}")

        # Load BGR images
        for file_name in os.listdir(bgr_data_path):
            file_path = os.path.join(bgr_data_path, file_name)
            print(f"Checking BGR file: {file_path}")  # Debug print
            if os.path.isfile(file_path):
                self.bgrs.append(file_path)
                print(f"Loaded BGR file: {file_path}")  # Confirming file load
            else:
                print(f"File does not exist or is not a file: {file_path}")

        # Check the length of loaded data
        print(f"Loaded {len(self.hypers)} hyper images.")
        print(f"Loaded {len(self.bgrs)} BGR images.")

        # Validate that both hypers and bgrs are loaded correctly
        if not self.hypers or not self.bgrs:
            print("Error: No hyper or BGR images loaded.")
            raise ValueError("Dataset is empty! Please check the dataset paths.")


        for i in range(len(hyper_list)):
            hyper_path = hyper_data_path + hyper_list[i]
            if 'mat' not in hyper_path:
                continue
            with h5py.File(hyper_path, 'r') as mat:
                hyper = np.float32(np.array(mat['cube']))
            hyper = np.transpose(hyper, [0, 2, 1])
            bgr_path = bgr_data_path + bgr_list[i]
            assert hyper_list[i].split('.')[0] == bgr_list[i].split('.')[0], 'Hyper and RGB come from different scenes.'
            # Load BGR image
            bgr = cv2.imread(bgr_path)
            if bgr is None:
                 print(f"Warning: BGR image not found at {bgr_path}")
                 continue  # Skip this iteration if the image is not found
            # Convert BGR to RGB if needed
            if bgr2rgb:
                 bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
             # Normalize BGR image
            bgr = np.float32(bgr)
            bgr = (bgr - bgr.min()) / (bgr.max() - bgr.min())  # Normalize to range [0, 1]
            bgr = np.transpose(bgr, [2, 0, 1])  # Transpose to channel-first format
            # Append hyper and BGR data to respective lists
            self.hypers.append(hyper)
            self.bgrs.append(bgr)
    
            print(f'Ntire2022 scene {i} is loaded.')  # Print the loading status

   # def __getitem__(self, idx):
       # hyper = self.hypers[idx]
       # bgr = self.bgrs[idx]
       # return np.ascontiguousarray(bgr), np.ascontiguousarray(hyper)



    # Convert both to PyTorch tensors

    def __getitem__(self, idx):
    # Load the hyperspectral data from .mat file using h5py
    	hyper_path = self.hypers[idx]
    	if isinstance(hyper_path, str):
          try:
            	with h5py.File(hyper_path, 'r') as f:
                # Use the correct key 'cube' for hyperspectral data
                    if 'cube' in f:
                        hyper = f['cube'][:]
                    else:
                        raise KeyError(f"Key 'cube' not found in {hyper_path}")
          except Exception as e:
            	raise ValueError(f"Failed to load hyperspectral data from {hyper_path}: {e}")
    	else:
        	raise TypeError(f"Expected 'hyper' to be a string path, but got type {type(hyper_path)}")

    # Convert hyper to a contiguous array and check for numerical type
    	hyper = np.ascontiguousarray(hyper)
    	if not np.issubdtype(hyper.dtype, np.number):
        	raise TypeError(f"Expected numerical data in 'hyper', but got dtype {hyper.dtype} at index {idx}.")

    # Load the BGR image from the file path
    	bgr_path = self.bgrs[idx]
    	bgr = cv2.imread(bgr_path)
    	if bgr is None:
        	raise ValueError(f"Failed to load BGR file: {bgr_path}")

    # Convert the BGR image to a contiguous array and check its data type
    	bgr = np.ascontiguousarray(bgr)
    	if not np.issubdtype(bgr.dtype, np.number):
        	raise TypeError(f"Expected numerical data in 'bgr', but got dtype {bgr.dtype} at index {idx}.")

    # Convert both to PyTorch tensors
    	bgr_tensor = torch.from_numpy(bgr).float()
    	hyper_tensor = torch.from_numpy(hyper).float()

    	return bgr_tensor, hyper_tensor 
    def __len__(self):
            return len(self.hypers)
